{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"\n# Online Python - IDE, Editor, Compiler, Interpreter\n\nimport numpy as np\nfrom numpy.linalg import norm \n    \ndef randomization(n):\n    \"\"\"\n    Arg:\n      n - an integer\n    Returns:\n      A - a randomly-generated nx1 Numpy array.\n    \"\"\"\n    #Your code here\n    \n\n    if n>0 and n==int:\n        A=np.random.rand([n, 1])\n    \n  \n        return A\n        raise NotImplementedError\n\ndef operations(h, w):\n    \"\"\"\n    Takes two inputs, h and w, and makes two Numpy arrays A and B of size\n    h x w, and returns A, B, and s, the sum of A and B.\n\n    Arg:\n      h - an integer describing the height of A and B\n      w - an integer describing the width of A and B\n    Returns (in this order):\n      A - a randomly-generated h x w Numpy array.\n      B - a randomly-generated h x w Numpy array.\n      s - the sum of A and B.\n    \"\"\"\n    #Your code here\n    if h>0 and w>0 and type(h)==int and type(w)==int:\n        A = np.random.rand(h, w)\n        B = np.random.rand(h, w)\n        s = A+B\n        return A,B,s\n    raise NotImplementedError\n\ndef norm(A, B):\n    \"\"\"\n    Takes two Numpy column arrays, A and B, and returns the L2 norm of their\n    sum.\n    Arg:\n      A - a Numpy array\n      B - a Numpy array\n    Returns:\n      s - the L2 norm of A+B.\n    \"\"\"\n    s = A + B\n\n    return np.linalg.norm(s)\n\n    raise NotImplementedError\n\ndef neural_network(inputs, weights):\n    \"\"\"\n     Takes an input vector and runs it through a 1-layer neural network\n     with a randomized weight matrix and one output.\n     Arg:\n       inputs - 2 x 1 NumPy array\n       weights - 2 x 1 NumPy array\n     Returns (in this order):\n       out - a 1 x 1 NumPy array, representing the output of the neural network\n    \"\"\"\n    z = np.tanh(weights.T.dot(inputs))\n\n    return z\n    raise NotImplementedError\n\ndef scalar_function(x, y):\n    \"\"\"\n    Returns the f(x,y) defined in the problem statement.\n    \"\"\"\n    #Your code here\n    \n    if x <= y:\n        return x*y\n    else:\n        return x/y\n    raise NotImplementedError\n\ndef vector_function(x, y):\n    \"\"\"\n    Make sure vector_function can deal with vector input x,y \n    \"\"\"\n    #Your code here\n    vfunc = np.vectorize(scalar_function)\n    return vfunc\n    raise NotImplementedError\n\ndef main():\n    #1) randomization function\n         x=int(input(\"enter a positive number: \"))\n         print(randomization(x))\n    #2) operations function\n          \n         x=int(input(\"Enter a positive number for x: \"))\n         y=int(input(\"Enter a positive number for y: \"))\n         A,B,s=operations(x, y)\n         print('A = ')\n         print(A)\n         print('B = ')\n         print(B)\n         print('Sum A and B = ')\n         print(s)\n        \n    #3) norm function\n         a=[1,3,5]\n         b=[1,4,2]\n         print(norm(a, b))\n    \n    #4) nerual network function\n         x=[1,0]\n         y=[0.38,0.55]\n         print (\" the output of nural network: \")\n         print ( neural_network(x, y))\n    #5) scal function\n         print (\" the output of scaler function  :\")\n         print (scalar_function(5, 3))\n    #6) vector function\n         print (\" the output of vector function  :\")\n         print( vector_function(6, 2))\n    \n    \n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}